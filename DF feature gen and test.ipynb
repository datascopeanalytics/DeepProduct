{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "from keras.applications import VGG16,imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import Image,display\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "def draw_bbox(bbox):\n",
    "    img = PIL.Image.open('Data/DeepFashion/'+bbox['image_name']).convert('RGBA')\n",
    "    \n",
    "    lx = bbox['x_1']\n",
    "    ly = bbox['y_1']\n",
    "    ux = bbox['x_2']\n",
    "    uy = bbox['y_2']\n",
    "    rect = PIL.Image.new('RGBA', img.size, (255,255,255,0))\n",
    "    d = ImageDraw.Draw(img)\n",
    "    d.rectangle(((lx,ly), (ux,uy)), outline=\"red\")\n",
    "    return PIL.Image.alpha_composite(img,rect)\n",
    "\n",
    "def gen_pairs(N,image_df,feature_matrix,metric='L2'):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    if metric == 'H':\n",
    "        bin_mat = (feature_matrix > 0)\n",
    "    for i in img_index:\n",
    "        img_feature = feature_matrix[i,:]\n",
    "        if metric == 'L2':\n",
    "            dist = np.sum((feature_matrix-img_feature)**2,axis=1)\n",
    "        elif metric == 'L1':\n",
    "            dist = np.sum(np.abs(feature_matrix-img_feature),axis=1)\n",
    "        elif metric == 'H':\n",
    "            img_feature = (img_feature>0)\n",
    "            dist = np.sum(np.logical_xor(img_feature,bin_mat),axis=1)\n",
    "        \n",
    "        j=1\n",
    "        match = np.argsort(dist)[j]\n",
    "        while dist[match]<=0:\n",
    "            j += 1\n",
    "            match = np.argsort(dist)[j]\n",
    "\n",
    "        display(draw_bbox(image_df.iloc[i]))\n",
    "        display(draw_bbox(image_df.iloc[match]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbox = pd.read_table('Data/DeepFashion/list_bbox.txt',sep='\\s+')\n",
    "cat = pd.read_table('Data/DeepFashion/list_category_img.txt',sep='\\s+')\n",
    "\n",
    "tops = bbox.iloc[cat[(cat.category_label>=1) & (cat.category_label<=20)].index]\n",
    "bottoms = bbox.iloc[cat[(cat.category_label>=21) & (cat.category_label<=36)].index]\n",
    "dresses = bbox.iloc[cat[(cat.category_label>36)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputShape = (224, 224)\n",
    "preprocess = imagenet_utils.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_resize_DF(bbox):\n",
    "    img = PIL.Image.open('Data/DeepFashion/'+bbox['image_name'])\n",
    "    lx = bbox['x_1']\n",
    "    ly = bbox['y_1']\n",
    "    ux = bbox['x_2']\n",
    "    uy = bbox['y_2']\n",
    "    \n",
    "    img = img.crop((lx,ly,ux,uy))\n",
    "    img = img.resize(inputShape, PIL.Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "def preprocess_DF(bbox):\n",
    "    image = crop_resize_DF(bbox)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    \n",
    "    return preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "subset = np.random.randint(bbox.shape[0],size=N)\n",
    "proc_img = []\n",
    "for i in subset:\n",
    "    proc_img.append(np.squeeze(preprocess_DF(bbox.iloc[i])))\n",
    "proc_img = np.array(proc_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = bbox.iloc[subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12042.240144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(proc_img)/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(bbox.iloc[subset],open('Data/feature_matrix/DF20000_bbox.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet')\n",
    "base_fc6 = Model(inputs=base_model.input,outputs=base_model.get_layer('fc1').output)\n",
    "base_fc7 = Model(inputs=base_model.input,outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 778865074406547787\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 360448000\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17026317379602066617\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute '0f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da684f097ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfc6_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_fc6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{.0f} s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute '0f'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fc6_base = base_fc6.predict(proc_img)\n",
    "print('{:.0f} s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 4096)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc6_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pickle.dump(fc6_base,open('Data/feature_matrix/FC6_base.p','wb'),pickle.HIGHEST_PROTOCOL)\n",
    "print('{:.0f} s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fc7_base = base_fc7.predict(proc_img)\n",
    "pickle.dump(fc7_base,open('Data/feature_matrix/FC7_base.p','wb'))\n",
    "print('{:.0f} s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "sub_trained = load_model('DF-Subset-Category-trained-7-24.h5')\n",
    "sub_fc6 = Model(inputs=sub_trained.input,outputs=sub_trained.get_layer('fc1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fc6_sub = sub_fc6.predict(proc_img)\n",
    "pickle.dump(fc6_sub,open('Data/feature_matrix/FC6_subset_trained.p','wb'))\n",
    "print('{:.0f} s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_trained = load_model('DF-Category-FULL-retrain.h5')\n",
    "full_fc6 = Model(inputs=full_trained.input,outputs=full_trained.get_layer('fc1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fc6_full = full_fc6.predict(proc_img)\n",
    "pickle.dump(fc6_full,open('Data/feature_matrix/FC6_full_trained.p','wb'))\n",
    "print('{:.0f} s'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cat = pd.read_table('Data/DeepFashion/list_category_img.txt',sep='\\s+')\n",
    "df['category_label'] = cat.iloc[df.index]['category_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "def draw_bbox(bbox):\n",
    "    img = PIL.Image.open('Data/DeepFashion/'+bbox['image_name']).convert('RGBA')\n",
    "    \n",
    "    lx = bbox['x_1']\n",
    "    ly = bbox['y_1']\n",
    "    ux = bbox['x_2']\n",
    "    uy = bbox['y_2']\n",
    "    rect = PIL.Image.new('RGBA', img.size, (255,255,255,0))\n",
    "    d = ImageDraw.Draw(img)\n",
    "    d.rectangle(((lx,ly), (ux,uy)), outline=\"red\")\n",
    "    return PIL.Image.alpha_composite(img,rect)\n",
    "\n",
    "def gen_pairs(N,image_df,feature_matrix,metric='L2'):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    if metric == 'H':\n",
    "        bin_mat = (feature_matrix > 0)\n",
    "    for i in img_index:\n",
    "        img_feature = feature_matrix[i,:]\n",
    "        if metric == 'L2':\n",
    "            dist = np.sum((feature_matrix-img_feature)**2,axis=1)\n",
    "        elif metric == 'L1':\n",
    "            dist = np.sum(np.abs(feature_matrix-img_feature),axis=1)\n",
    "        elif metric == 'H':\n",
    "            img_feature = (img_feature>0)\n",
    "            dist = np.sum(np.logical_xor(img_feature,bin_mat),axis=1)\n",
    "        \n",
    "        j=1\n",
    "        match = np.argsort(dist)[j]\n",
    "        while dist[match]<=0:\n",
    "            j += 1\n",
    "            match = np.argsort(dist)[j]\n",
    "\n",
    "        display(draw_bbox(image_df.iloc[i]))\n",
    "        display(draw_bbox(image_df.iloc[match]))\n",
    "        \n",
    "def test_pairs(N,image_df,feature_matrix,metric='L2'):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    cat_match = []\n",
    "    if metric == 'H':\n",
    "        bin_mat = (feature_matrix > 0)\n",
    "    for i in img_index:\n",
    "        img_feature = feature_matrix[i,:]\n",
    "        if metric == 'L2':\n",
    "            dist = np.sum((feature_matrix-img_feature)**2,axis=1)\n",
    "        elif metric == 'L1':\n",
    "            dist = np.sum(np.abs(feature_matrix-img_feature),axis=1)\n",
    "        elif metric == 'H':\n",
    "            img_feature = (img_feature>0)\n",
    "            dist = np.sum(np.logical_xor(img_feature,bin_mat),axis=1)\n",
    "        \n",
    "        j=1\n",
    "        match = np.argsort(dist)[j]\n",
    "        while dist[match]<=0:\n",
    "            j += 1\n",
    "            match = np.argsort(dist)[j]\n",
    "\n",
    "        cat_match.append(image_df.iloc[i]['category_label'] == image_df.iloc[match]['category_label'])\n",
    "        \n",
    "    return cat_match\n",
    "\n",
    "def random_pairs(N,image_df):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    match_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    return (image_df.iloc[img_index]['category_label'].values\n",
    "            == image_df.iloc[match_index]['category_label'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest(dist):\n",
    "    j=1\n",
    "    sort = np.argsort(dist)\n",
    "        \n",
    "    while dist[sort[j]]<=0:\n",
    "        j += 1\n",
    "        \n",
    "    return sort[j]\n",
    "\n",
    "def test_pairs_all_D(N,image_df,feature_matrix):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    cat_match = {'L2':[],'L1':[],'H':[]}\n",
    "  \n",
    "    bin_mat = (feature_matrix > 0)\n",
    "    \n",
    "    for i in img_index:\n",
    "        img_feature = feature_matrix[i,:]\n",
    "        L2_dist = np.sum((feature_matrix-img_feature)**2,axis=1)\n",
    "        L1_dist = np.sum(np.abs(feature_matrix-img_feature),axis=1)\n",
    "        img_feature = (img_feature>0)\n",
    "        H_dist = np.sum(np.logical_xor(img_feature,bin_mat),axis=1)\n",
    "        \n",
    "        L2_match = find_nearest(L2_dist)\n",
    "        L1_match = find_nearest(L1_dist)\n",
    "        H_match = find_nearest(H_dist)\n",
    "\n",
    "        cat_match['L2'].append(image_df.iloc[i]['category_label'] == image_df.iloc[L2_match]['category_label'])\n",
    "        cat_match['L1'].append(image_df.iloc[i]['category_label'] == image_df.iloc[L1_match]['category_label'])\n",
    "        cat_match['H'].append(image_df.iloc[i]['category_label'] == image_df.iloc[H_match]['category_label'])\n",
    "        \n",
    "    return cat_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_scores(score):\n",
    "    print('L1: {:.4f}'.format(np.mean(score['L1'])))\n",
    "    print('L2: {:.4f}'.format(np.mean(score['L2'])))\n",
    "    print('H: {:.4f}'.format(np.mean(score['H'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.108\n"
     ]
    }
   ],
   "source": [
    "r_score = random_pairs(1000,df)\n",
    "print('P@1: {}'.format(np.mean(r_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 0.4650\n",
      "L2: 0.4640\n",
      "H: 0.4760\n"
     ]
    }
   ],
   "source": [
    "fc6_base_score = test_pairs_all_D(1000,df,fc6_base)\n",
    "print_scores(fc6_base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 0.4320\n",
      "L2: 0.4040\n",
      "H: 0.4520\n"
     ]
    }
   ],
   "source": [
    "fc7_base_score = test_pairs_all_D(1000,df,fc7_base)\n",
    "print_scores(fc7_base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 0.5330\n",
      "L2: 0.5420\n",
      "H: 0.5360\n"
     ]
    }
   ],
   "source": [
    "fc6_sub_score = test_pairs_all_D(1000,df,fc6_sub)\n",
    "print_scores(fc6_sub_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 0.5670\n",
      "L2: 0.6000\n",
      "H: 0.5540\n"
     ]
    }
   ],
   "source": [
    "fc6_full_score = test_pairs_all_D(1000,df,fc6_full)\n",
    "print_scores(fc6_full_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pairs(N,k,image_df,feature_matrix,metric='L2'):\n",
    "    img_index = np.random.randint(image_df.shape[0],size=N)\n",
    "    \n",
    "    if metric == 'H':\n",
    "        bin_mat = (feature_matrix > 0)\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    for i in img_index:\n",
    "        img_feature = feature_matrix[i,:]\n",
    "        if metric == 'L2':\n",
    "            dist = np.sum((feature_matrix-img_feature)**2,axis=1)\n",
    "        elif metric == 'L1':\n",
    "            dist = np.sum(np.abs(feature_matrix-img_feature),axis=1)\n",
    "        elif metric == 'H':\n",
    "            img_feature = (img_feature>0)\n",
    "            dist = np.sum(np.logical_xor(img_feature,bin_mat),axis=1)\n",
    "        \n",
    "        j=1\n",
    "        match = np.argsort(dist)[j:(j+k)]\n",
    "        while dist[match[0]]<=0:\n",
    "            j += 1\n",
    "            match = np.argsort(dist)[j:(j+k)]\n",
    "        \n",
    "        s = image_df.iloc[i]['image_name']\n",
    "        for m in match:\n",
    "            s = s + \"\\t\" + image_df.iloc[m]['image_name']\n",
    "        pairs.append(s)\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fc6_full_trained_H.txt', 'w') as f:\n",
    "    f.write('\\n'.join(write_pairs(300,3,df,fc6_full,'H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fc6_full_trained_L2.txt', 'w') as f:\n",
    "    f.write('\\n'.join(write_pairs(300,3,df,fc6_full,'L2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fc6_subset_trained_L2.txt', 'w') as f:\n",
    "    f.write('\\n'.join(write_pairs(300,3,df,fc6_sub,'L2')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fc6_base_H.txt', 'w') as f:\n",
    "    f.write('\\n'.join(write_pairs(300,3,df,fc6_base,'H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fc7_base_H.txt', 'w') as f:\n",
    "    f.write('\\n'.join(write_pairs(300,3,df,fc7_base,'H')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-86176d57924a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfc6_full_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc6_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \"\"\"\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0mneighbors_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors_nn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             P = _joint_probabilities_nn(distances, neighbors_nn,\n\u001b[0;32m--> 766\u001b[0;31m                                         self.perplexity, self.verbose)\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joint_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_joint_probabilities_nn\u001b[0;34m(distances, neighbors, desired_perplexity, verbose)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconditional_P\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconditional_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0msum_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMACHINE_EPSILON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquareform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMACHINE_EPSILON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36msquareform\u001b[0;34m(X, force, checks)\u001b[0m\n\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0;31m# Create a vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[0;31m# Since the C code does not support striding using strides.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE()\n",
    "fc6_full_embed = tsne.fit_transform(fc6_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Plots an image at each x and y location. \n",
    "def plotImage(x, y, image, ax):\n",
    "    im = OffsetImage(load_img(image,target_size=inputShape), zoom=0.15)\n",
    "    ab = AnnotationBbox(im, (x, y), xycoords='data', frameon=False)\n",
    "    ax.add_artist(ab)\n",
    "\n",
    "# Create figure\n",
    "def plot_tsne(N,embed,image_df,file):\n",
    "    fig = plt.figure(figsize=(20,20),dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for i in range(N):\n",
    "        plotImage(embed[i,0],embed[i,1],\n",
    "                  'Data/DeepFashion/'+image_df.iloc[i]['image_name'],ax)\n",
    "\n",
    "    ax.set_ylim(np.min(embed[:N,1]),np.max(embed[:N,1]))\n",
    "    ax.set_xlim(np.min(embed[:N,0]),np.max(embed[:N,0]))\n",
    "\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fc6_full_embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f431ee08aa91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_tsne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfc6_full_embed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DF_20000_FC6_full_tsne.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fc6_full_embed' is not defined"
     ]
    }
   ],
   "source": [
    "plot_tsne(250,fc6_full_embed,bbox.iloc[subset],'DF_20000_FC6_full_tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc6_base_embed = tsne.fit_transform(fc6_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_tsne(250,fc6_base_embed,bbox.iloc[subset],'DF_20000_FC6_base_tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
