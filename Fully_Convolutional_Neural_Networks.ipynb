{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Neural Networks\n",
    "\n",
    "Objectives:\n",
    "- Load a CNN model pre-trained on ImageNet\n",
    "- Transform the network into a Fully Convolutional Network \n",
    "- Apply the network perform weak segmentation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94478336/94653016 [============================>.] - ETA: 0s(None, None, None, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet50\n",
    "# We use include_top = False for now,\n",
    "# as we'll import output Dense Layer later\n",
    "\n",
    "from tensorflow.contrib import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(include_top=False)\n",
    "\n",
    "print(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.core.Activation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res5c = base_model.layers[-2]\n",
    "type(res5c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res5c.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.pooling.AveragePooling2D"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool = base_model.layers[-1]\n",
    "type(avg_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7, 7), (7, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool.pool_size, avg_pool.strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully convolutional ResNet\n",
    "\n",
    "- Out of the `res5c` residual block, the resnet outputs a tensor of shape $W \\times H \\times 2048$. \n",
    "- For the default ImageNet input, $224 \\times 224$, the output size is $7 \\times 7 \\times 2048$\n",
    "- After this bloc, the ResNet uses an average pooling `AveragePooling2D(pool_size=(7, 7))` with `(7, 7)` strides which divides by 7 the width and height\n",
    "\n",
    "#### Regular ResNet layers \n",
    "\n",
    "The regular ResNet head after the base model is as follows: \n",
    "```py\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1000)(x)\n",
    "x = Softmax()(x)\n",
    "```\n",
    "\n",
    "Here is the full definition of the model: https://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py\n",
    "\n",
    "#### Our Version\n",
    "\n",
    "- To keep spatial information as much as possible, we will remove the average pooling.\n",
    "- We want to retrieve the labels information, which is stored in the Dense layer. We will load these weights afterwards\n",
    "- We will change the Dense Layer to a Convolution2D layer to keep spatial information, to output a $W \\times H \\times 1000$.\n",
    "- We can use a kernel size of (1, 1) for that new Convolution2D layer to pass the spatial organization of the previous layer unchanged.\n",
    "- We want to apply a softmax only on the last dimension so as to preserve the $W \\times H$ spatial information.\n",
    "\n",
    "#### A custom Softmax\n",
    "\n",
    "We build the following Custom Layer to apply a softmax only to the last dimension of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "# A custom layer in Keras must implement the four following methods:\n",
    "class SoftmaxMap(Layer):\n",
    "    # Init function\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "        self.axis = axis\n",
    "        super(SoftmaxMap, self).__init__(**kwargs)\n",
    "\n",
    "    # There's no parameter, so we don't need this one\n",
    "    def build(self,input_shape):\n",
    "        pass\n",
    "\n",
    "    # This is the layer we're interested in: \n",
    "    # very similar to the regular softmax but note the additional\n",
    "    # that we accept x.shape == (batch_size, w, h, n_classes)\n",
    "    # which is not the case in Keras by default.\n",
    "    def call(self, x, mask=None):\n",
    "        e = K.exp(x - K.max(x, axis=self.axis, keepdims=True))\n",
    "        s = K.sum(e, axis=self.axis, keepdims=True)\n",
    "        return e / s\n",
    "\n",
    "    # The output shape is the same as the input shape\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can use this layer to normalize the classes probabilities of some random spatial predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 4, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples, w, h, n_classes = 10, 3, 4, 5\n",
    "random_data = np.random.randn(n_samples, w, h, n_classes)\n",
    "random_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because those predictions are random, if we some accross the classes dimensions we get random values instead of class probabilities that would need to some to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7761751 , -1.85326499, -2.66958759, -0.47682411],\n",
       "       [ 3.03376207, -4.34344828, -1.12612413, -2.50163954],\n",
       "       [-1.76870607,  0.35772155, -0.48383823, -0.57624452]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data[0].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap the `SoftmaxMap` class into a test model to process our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsteins/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:615: UserWarning: Class `__main__.SoftmaxMap` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  output_shape = self.compute_output_shape(input_shape)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 3, 4, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential([SoftmaxMap(input_shape=(w, h, n_classes))])\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 4, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_mapped_data = model.predict(random_data)\n",
    "softmax_mapped_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension now approximately sum to one, we can therefore be used as class probabilities (or parameters for a multinouli distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  0.99999994],\n",
       "       [ 0.99999988,  1.        ,  1.        ,  1.        ],\n",
       "       [ 0.99999988,  1.        ,  1.        ,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_mapped_data[0].sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise **\n",
    "- What is the shape of the convolution kernel we want to apply to replace the Dense ?\n",
    "- Build the fully convolutional model as described above.\n",
    "- You may introspect the last elements of `base_model.layers` to find which layer to remove\n",
    "- You may use the Keras `Convolution2D(output_channels, filter_w, filter_h)` layer and our `SotfmaxMap` to normalize the result as per-class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsteins/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"in...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Model\n",
    "\n",
    "input = base_model.layers[0].input\n",
    "\n",
    "# TODO: compute per-area class probabilites\n",
    "output = input\n",
    "\n",
    "fully_conv_ResNet = Model(input=input, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/fully_conv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following random data to check that it's possible to run a forward pass on a random RGB image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps = fully_conv_ResNet.predict(np.random.randn(1, 200, 300, 3))\n",
    "prediction_maps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you explain the resulting output shape?\n",
    "\n",
    "The class probabilities should sum to one in each area of the output map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_maps.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dense weights\n",
    "\n",
    "- We provide the weights and bias of the last Dense layer of ResNet50 in file `weights_dense.h5`\n",
    "- Our last layer is now a 1x1 convolutional layer instead of a fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = 'weights_dense.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c13e45a0b67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights_dense.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nsteins/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nsteins/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1490026758621/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/Users/ilan/minonda/conda-bld/h5py_1490026758621/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/Users/ilan/minonda/conda-bld/h5py_1490026758621/work/h5py/h5f.c:2123)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = 'weights_dense.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "h5f = h5py.File('weights_dense.h5','r')\n",
    "w = h5f['w'][:]\n",
    "b = h5f['b'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = fully_conv_ResNet.layers[-2]\n",
    "\n",
    "print(\"Loaded weight shape:\", w.shape)\n",
    "print(\"Last conv layer weights shape:\", last_layer.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the weights\n",
    "w_reshaped = w.reshape((1, 1, 2048, 1000))\n",
    "\n",
    "# set the conv layer weights\n",
    "last_layer.set_weights([w_reshaped, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A forward pass\n",
    "\n",
    "- We define the following function to test our new network. \n",
    "- It resizes the input to a given size, then uses `model.predict` to compute the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "def forward_pass_resize(img_path, img_size):\n",
    "    img_raw = imread(img_path)\n",
    "    print(\"img shape before resizing: %s\" % (img_raw.shape,))\n",
    "    img = imresize(img_raw, size=img_size).astype(\"float32\")\n",
    "    img = preprocess_input(img[np.newaxis])\n",
    "    print(\"img batch size shape before forward pass:\", img.shape)\n",
    "    z = fully_conv_ResNet.predict(img)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = forward_pass_resize(\"dog.jpg\", (800, 600))\n",
    "print(\"prediction map shape\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding dog-related classes\n",
    "ImageNet uses an ontology of concepts, from which classes are derived. A synset corresponds to a node in the ontology.\n",
    "\n",
    "For example species of dogs are children nodes of the synset `dog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper file for importing synsets from imagenet\n",
    "import imagenet_tool\n",
    "synset = \"n02084071\" # synset corresponding to dogs\n",
    "ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "print(\"All dog classes ids (%d):\" % len(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dog_id in ids[:10]:\n",
    "    print(imagenet_tool.id_to_words(dog_id))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised heatmap of the class \"dog\"\n",
    "\n",
    "The following function builds a heatmap from a forward pass. It sums the representation for all ids corresponding to a synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_heatmap(z, synset):\n",
    "    ids = imagenet_tool.synset_to_dfs_ids(synset)\n",
    "    ids = np.array([id_ for id_ in ids if id_ is not None])\n",
    "    x = z[0, :, :, ids].sum(axis=0)\n",
    "    print(\"size of heatmap: \" + str(x.shape))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_img_and_heatmap(img_path, heatmap):\n",
    "    dog = imread(img_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(dog)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(heatmap, interpolation='nearest', cmap=\"viridis\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "- What is the size of the heatmap compared to the input image?\n",
    "- Build 3 dog heatmaps from `\"dog.jpg\"`, with the following sizes:\n",
    "  - `(400, 640)`\n",
    "  - `(800, 1280)`\n",
    "  - `(1600, 2560)`\n",
    "- What do you observe? \n",
    "\n",
    "You may plot a heatmap using the above function `display_img_and_heatmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog synset\n",
    "s = \"n02084071\"\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/build_heatmaps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the 3 heatmaps\n",
    "By combining the heatmaps at different scales, we obtain a much better information about the location of the dog.\n",
    "\n",
    "**Bonus**\n",
    "- Combine the three heatmap by resizing them to a similar shape, and averaging them\n",
    "- A geometric norm will work better than standard average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/geom_avg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**\n",
    "\n",
    "Train the parameters of the last Convolution / classification layer of this segmentation network on classes of your choice on the MS COCO 2016 dataset:\n",
    "\n",
    "http://mscoco.org/dataset/#overview\n",
    "\n",
    "- Use the GPU to precompute the activations of a headless and convolutionalized ResNet50 or Xception model;\n",
    "- Initialize the weights of a new Convolution2D(n_classes, 1, 1) at random;\n",
    "- Train the top of the segmentation model on class label data extracted from the  MS COCO 2016 dataset;\n",
    "- Start with a single low resolution model. Then add multi-scale and see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
